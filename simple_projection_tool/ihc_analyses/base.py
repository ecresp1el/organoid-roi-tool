"""Reusable scaffolding for immunohistochemistry projection analyses.

The goal of this module is to give every downstream biological question a
predictable place to put code. Each analysis object that works with the TIFF
projections generated by :mod:`simple_channel_projections` should inherit from
:class:`ProjectionAnalysis` and fill in the hooks for loading data, processing
it, and producing figures or tables. Scientists can therefore copy an existing
analysis, change only the biological logic, and immediately gain a working
pipeline that saves intermediate files to disk.
"""

from __future__ import annotations

import abc
from pathlib import Path
import subprocess
import sys
from typing import Dict, Iterable, List, Optional, Sequence

import pandas as pd

try:  # Matplotlib is optional for analyses that never create figures.
    from matplotlib.figure import Figure
except Exception:  # pragma: no cover - fallback when matplotlib is unavailable
    Figure = None  # type: ignore[misc,assignment]


class ProjectionAnalysis(abc.ABC):
    """Template for building reproducible analysis pipelines.

    Subclasses are expected to implement two mandatory steps:

    ``import_data``
        Locate the exported TIFFs and return a manifest (``pandas.DataFrame``)
        describing what will be processed. The base class stores this manifest
        for later saving.

    ``process_data``
        Take the manifest, load each file, and calculate the per-image
        statistics of interest. The returned ``DataFrame`` is likewise stored.

    Optional hooks such as :meth:`run_statistics` and :meth:`generate_plots`
    can be overridden when an analysis needs them. The :meth:`run` method calls
    each stage in order so a scientist can execute the entire pipeline with a
    single command. Any tables or figures produced by the analysis are saved
    beneath ``<output_dir>/analysis_pipeline`` so collaborators always know
    where to look for derived artefacts.
    """

    #: Human readable identifier used for folder names and command line choices.
    name: str = "projection_analysis"

    def __init__(
        self,
        base_path: Path | str,
        *,
        projection_dir_name: str = "simple_projections",
        output_dir: Optional[Path | str] = None,
        channel_filter: Optional[Sequence[str]] = None,
    ) -> None:
        """Set up common paths used by the analysis."""

        self.base_path = Path(base_path).expanduser().resolve()
        self.projection_dir_name = projection_dir_name
        self.projection_root = self.base_path / self.projection_dir_name
        self.output_dir = (
            Path(output_dir).expanduser().resolve()
            if output_dir is not None
            else self.base_path / "analysis_results" / self.name
        )

        # Subclasses can register additional tables for saving once the pipeline
        # finishes running.
        self.additional_tables: Dict[str, pd.DataFrame] = {}

        # Restrict processing to a subset of channels when requested. Channel
        # names are normalised to match the filenames produced by the projection
        # export utility (case-insensitive, punctuation stripped).
        self.channel_filter_names: tuple[str, ...] = tuple(channel_filter or ())
        normalised = {
            self._normalise_channel_name(name)
            for name in self.channel_filter_names
            if name
        }
        self.channel_filter: Optional[set[str]] = normalised or None

        # Derived outputs (tables, plots) are stored beneath ``analysis_pipeline``
        # to emphasise that they originate from a downstream analysis stage. When
        # channels are filtered we create a dedicated subdirectory keyed by the
        # channel selection (e.g. ``analysis_pipeline/lhx6``).
        self._configure_pipeline_dirs()

        # ``save_outputs`` and ``save_figure`` populate these lists so the CLI
        # can report exactly what was created during the run.
        self.saved_table_paths: List[Path] = []
        self.saved_figure_paths: List[Path] = []
        self.per_image_summary_paths: List[Path] = []

        # The manifest lists every file we plan to inspect. ``results`` stores
        # the processed measurements calculated from those files. Subclasses
        # fill these with pandas DataFrames so downstream steps (saving, plots)
        # can reuse them without needing to re-run heavy computations.
        self.manifest: Optional[pd.DataFrame] = None
        self.results: Optional[pd.DataFrame] = None

    # ------------------------------------------------------------------
    # Pipeline orchestration
    # ------------------------------------------------------------------
    def run(self) -> None:
        """Execute the end-to-end pipeline for the analysis."""

        self.saved_table_paths.clear()
        self.saved_figure_paths.clear()
        self.per_image_summary_paths.clear()
        self.additional_tables.clear()

        if self.channel_filter_names:
            print(
                f"[{self.name}] Restricting to channels: "
                f"{', '.join(self.channel_filter_names)}",
                flush=True,
            )

        self._ensure_projection_exports()

        print(f"[{self.name}] Importing projection manifest ...", flush=True)
        self.manifest = self.import_data()
        manifest_len = len(self.manifest) if self.manifest is not None else 0
        print(
            f"[{self.name}]  -> catalogued {manifest_len} projection file(s).",
            flush=True,
        )

        print(f"[{self.name}] Processing projection statistics ...", flush=True)
        self.results = self.process_data(self.manifest)
        results_len = len(self.results) if self.results is not None else 0
        print(
            f"[{self.name}]  -> generated per-image statistics for {results_len} TIFF(s).",
            flush=True,
        )

        print(f"[{self.name}] Running group statistics ...", flush=True)
        self.run_statistics()
        print(f"[{self.name}]  -> group statistics stage complete.", flush=True)

        print(f"[{self.name}] Creating figures ...", flush=True)
        self.generate_plots()
        print(
            f"[{self.name}]  -> created {len(self.saved_figure_paths)} figure(s) for export.",
            flush=True,
        )

        print(f"[{self.name}] Creating per-image summaries ...", flush=True)
        self.generate_per_image_summaries()
        print(
            f"[{self.name}]  -> generated {len(self.per_image_summary_paths)} per-image figure(s).",
            flush=True,
        )

        print(f"[{self.name}] Saving data tables ...", flush=True)
        self.save_outputs()
        print(
            f"[{self.name}]  -> wrote {len(self.saved_table_paths)} CSV table(s) to disk.",
            flush=True,
        )

        self.export_results()

    # ------------------------------------------------------------------
    # Mandatory steps
    # ------------------------------------------------------------------
    @abc.abstractmethod
    def import_data(self) -> pd.DataFrame:
        """Discover and catalogue the projection files used by the analysis."""

    @abc.abstractmethod
    def process_data(self, manifest: pd.DataFrame) -> pd.DataFrame:
        """Perform the core numerical processing for the analysis."""

    # ------------------------------------------------------------------
    # Optional steps for subclasses to extend
    # ------------------------------------------------------------------
    def run_statistics(self) -> None:
        """Run statistical comparisons across processed results."""

    def generate_plots(self) -> None:
        """Produce figures summarising the analysis."""

    def generate_per_image_summaries(self) -> None:
        """Produce per-image summary figures (image + statistics)."""

        self.per_image_summary_paths.clear()
        if self.results is None or self.results.empty:
            return

        try:  # Lazily import heavy dependencies.
            import matplotlib.pyplot as plt  # type: ignore
            import numpy as np  # type: ignore
            import tifffile as tiff  # type: ignore
        except Exception as exc:  # pragma: no cover - environment dependent
            print(
                f"[{self.name}]     Skipping per-image summaries (missing dependency): {exc}",
                flush=True,
            )
            return

        from numbers import Number

        stats_fields = [
            ("pixel_count", "Pixel count"),
            ("pixel_mean", "Pixel mean"),
            ("pixel_median", "Pixel median"),
            ("pixel_std", "Pixel std"),
            ("pixel_max", "Pixel max"),
            ("ci_low", "CI low"),
            ("ci_high", "CI high"),
        ]

        for row in self.results.itertuples():
            image_path = Path(getattr(row, "path"))
            if not image_path.exists():
                print(f"[{self.name}]     Skipping missing TIFF: {image_path}", flush=True)
                continue

            try:
                image = tiff.imread(image_path)
            except Exception as exc:  # pragma: no cover - I/O dependent
                print(f"[{self.name}]     Failed to read {image_path}: {exc}", flush=True)
                continue

            if image.ndim != 2:
                image = np.squeeze(image)

            vmin = float(np.percentile(image, 1.0))
            vmax = float(np.percentile(image, 99.5))
            if vmax <= vmin:
                vmin = float(np.min(image))
                vmax = float(np.max(image))

            figure, axes = plt.subplots(1, 2, figsize=(10, 5), constrained_layout=True)

            im = axes[0].imshow(image, cmap="gray", vmin=vmin, vmax=vmax)
            axes[0].set_title(
                f"{getattr(row, 'channel_marker', getattr(row, 'channel', 'channel')).strip()}\n"
                f"{getattr(row, 'projection_type', '').upper()} projection"
            )
            cbar = figure.colorbar(im, ax=axes[0], fraction=0.046, pad=0.04)
            cbar.set_label("Pixel intensity")
            axes[0].set_xticks([])
            axes[0].set_yticks([])

            stats_lines = [
                f"filename: {getattr(row, 'filename', image_path.name)}",
                f"sample_id: {getattr(row, 'sample_id', 'n/a')}",
                f"group: {getattr(row, 'group', 'n/a')}",
                f"channel: {getattr(row, 'channel_canonical', getattr(row, 'channel', 'n/a'))}",
                f"display range: [{vmin:.2f}, {vmax:.2f}]",
            ]
            for column, label in stats_fields:
                value = getattr(row, column, None)
                if value is None or pd.isna(value):
                    continue
                if isinstance(value, Number):
                    stats_lines.append(f"{label}: {float(value):.3f}")
                else:
                    stats_lines.append(f"{label}: {value}")

            axes[1].axis("off")
            axes[1].text(
                0.0,
                1.0,
                "\n".join(stats_lines),
                transform=axes[1].transAxes,
                va="top",
                ha="left",
                fontsize=10,
                family="monospace",
            )

            group_value = str(getattr(row, "group", "unknown"))
            group_slug = self._slugify(group_value)
            per_image_dir = self.figures_dir / "per_image_summaries" / group_slug
            per_image_dir.mkdir(parents=True, exist_ok=True)

            filename_label = getattr(row, "filename", image_path.name)
            sample_slug = self._slugify(str(getattr(row, "sample_id", "sample")))
            file_slug = self._slugify(Path(filename_label).stem)
            stem = f"per_image_summaries/{group_slug}/{sample_slug}__{file_slug}"
            metadata = {
                "Creator": self.name,
                "Description": "Per-image summary linking projection pixel statistics to the TIFF.",
            }
            self.save_figure(figure, stem, formats=("png",), dpi=150, metadata=metadata)
            plt.close(figure)

            saved_path = per_image_dir / f"{sample_slug}__{file_slug}.png"
            self.per_image_summary_paths.append(saved_path)

    def save_outputs(self) -> None:
        """Persist intermediate artefacts such as CSV files."""

        self.pipeline_dir.mkdir(parents=True, exist_ok=True)
        self.data_dir.mkdir(parents=True, exist_ok=True)

        if self.manifest is not None:
            manifest_path = self.data_dir / "manifest.csv"
            self.manifest.to_csv(manifest_path, index=False)
            self.saved_table_paths.append(manifest_path)
            print(
                f"[{self.name}]     saved manifest -> {manifest_path}",
                flush=True,
            )

        if self.results is not None:
            results_path = self.data_dir / "results.csv"
            self.results.to_csv(results_path, index=False)
            self.saved_table_paths.append(results_path)
            print(
                f"[{self.name}]     saved per-image results -> {results_path}",
                flush=True,
            )

        for filename, table in self.additional_tables.items():
            target = filename if filename.lower().endswith(".csv") else f"{filename}.csv"
            table_path = self.data_dir / target
            table.to_csv(table_path, index=False)
            self.saved_table_paths.append(table_path)
            print(f"[{self.name}]     saved table -> {table_path}", flush=True)

    # ------------------------------------------------------------------
    # Convenience helpers for subclasses
    # ------------------------------------------------------------------
    def register_table(self, filename: str, table: pd.DataFrame) -> None:
        """Queue an additional table to be written by :meth:`save_outputs`."""

        if not filename:
            raise ValueError("filename must be a non-empty string")
        self.additional_tables[filename] = table

    def save_figure(
        self,
        figure: Figure,
        stem: str,
        *,
        formats: Sequence[str] = ("svg", "png"),
        dpi: int = 300,
        metadata: Optional[Dict[str, str]] = None,
    ) -> None:
        """Persist a Matplotlib figure in the analysis figures directory."""

        if Figure is None:
            raise RuntimeError(
                "matplotlib is required to save figures but could not be imported."
            )
        if not stem:
            raise ValueError("stem must be a non-empty string")

        self.figures_dir.mkdir(parents=True, exist_ok=True)
        for ext in formats:
            ext = ext.lower().lstrip(".")
            output_path = self.figures_dir / f"{stem}.{ext}"
            output_path.parent.mkdir(parents=True, exist_ok=True)
            save_kwargs = {
                "format": ext,
                "dpi": dpi,
                "bbox_inches": "tight",
            }
            if metadata:
                if ext == "svg":
                    allowed = {"Creator", "Title", "Description", "Date"}
                    filtered = {key: value for key, value in metadata.items() if key in allowed}
                    if filtered:
                        save_kwargs["metadata"] = filtered
                else:
                    save_kwargs["metadata"] = metadata
            figure.savefig(output_path, **save_kwargs)
            self.saved_figure_paths.append(output_path)
            print(f"[{self.name}]     saved figure -> {output_path}", flush=True)

    def export_results(self) -> None:
        """Hook for exporting artefacts to external systems."""

        # Subclasses can override this to push data to collaborators or shared
        # drives. The default implementation intentionally does nothing.
        return None

    # ------------------------------------------------------------------
    # Channel helpers
    # ------------------------------------------------------------------
    @staticmethod
    def _normalise_channel_name(name: str) -> str:
        """Return a case-insensitive, sanitised channel identifier."""

        cleaned = "".join(
            char if char.isalnum() or char in {"-", "_"} else "_"
            for char in name
        )
        cleaned = cleaned.strip("_.")
        return cleaned.lower()

    def _channel_is_selected(self, channel: str) -> bool:
        """Return True when the supplied channel passes the filter."""

        if self.channel_filter is None:
            return True
        return self._normalise_channel_name(channel) in self.channel_filter

    def _filter_channels(self, channels: Iterable[str]) -> list[str]:
        """Filter an iterable of channels using the current selection."""

        return [
            channel
            for channel in channels
            if self._channel_is_selected(channel)
        ]

    def _slugify(self, value: str) -> str:
        """Return a filesystem-safe slug derived from ``value``."""

        return self._normalise_channel_name(value)

    def _ensure_projection_exports(self) -> None:
        """Verify projection exports exist; run the generator when missing."""

        if not self.base_path.exists():
            raise FileNotFoundError(f"Base path {self.base_path} does not exist.")

        if self.projection_root.exists() and any(self.projection_root.iterdir()):
            print(
                f"[{self.name}] Found existing simple projections in {self.projection_root}.",
                flush=True,
            )
            return

        print(
            f"[{self.name}] No projections detected in {self.projection_root}.",
            flush=True,
        )
        script_path = Path(__file__).resolve().parent.parent / "simple_channel_projections.py"
        if not script_path.exists():
            raise FileNotFoundError(
                f"Projection generator script {script_path} is missing."
            )

        cmd = [
            sys.executable,
            str(script_path),
            "--source",
            str(self.base_path),
        ]
        print(
            f"[{self.name}] Launching simple_channel_projections to build exports...",
            flush=True,
        )
        result = subprocess.run(cmd, check=False)
        if result.returncode != 0:
            raise RuntimeError(
                f"simple_channel_projections failed with exit code {result.returncode}."
            )
        if not self.projection_root.exists() or not any(self.projection_root.iterdir()):
            raise FileNotFoundError(
                f"Projection generator completed but {self.projection_root} is still missing."
            )
        print(
            f"[{self.name}] simple_channel_projections completed; projections ready in {self.projection_root}.",
            flush=True,
        )

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------
    def _configure_pipeline_dirs(self) -> None:
        """Set up channel-aware pipeline directories."""

        slug = self._derive_channel_context_slug()
        self.channel_context_slug = slug
        self.pipeline_root = self.output_dir / "analysis_pipeline"
        self.pipeline_dir = self.pipeline_root / slug
        self.data_dir = self.pipeline_dir / "data"
        self.figures_dir = self.pipeline_dir / "figures"

    def _derive_channel_context_slug(self) -> str:
        """Return a filesystem-friendly slug describing the channel filter."""

        if not self.channel_filter_names:
            return "all_channels"
        slug_parts: list[str] = []
        seen: set[str] = set()
        for name in self.channel_filter_names:
            normalised = self._normalise_channel_name(name)
            if normalised and normalised not in seen:
                slug_parts.append(normalised)
                seen.add(normalised)
        return "__".join(slug_parts) if slug_parts else "all_channels"
