"""Reusable scaffolding for immunohistochemistry projection analyses.

The goal of this module is to give every downstream biological question a
predictable place to put code. Each analysis object that works with the TIFF
projections generated by :mod:`simple_channel_projections` should inherit from
:class:`ProjectionAnalysis` and fill in the hooks for loading data, processing
it, and producing figures or tables. Scientists can therefore copy an existing
analysis, change only the biological logic, and immediately gain a working
pipeline that saves intermediate files to disk.
"""

from __future__ import annotations

import abc
from pathlib import Path
from typing import Dict, Iterable, Optional, Sequence

import pandas as pd

try:  # Matplotlib is optional for analyses that never create figures.
    from matplotlib.figure import Figure
except Exception:  # pragma: no cover - fallback when matplotlib is unavailable
    Figure = None  # type: ignore[misc,assignment]


class ProjectionAnalysis(abc.ABC):
    """Template for building reproducible analysis pipelines.

    Subclasses are expected to implement two mandatory steps:

    ``import_data``
        Locate the exported TIFFs and return a manifest (``pandas.DataFrame``)
        describing what will be processed. The base class stores this manifest
        for later saving.

    ``process_data``
        Take the manifest, load each file, and calculate the per-image
        statistics of interest. The returned ``DataFrame`` is likewise stored.

    Optional hooks such as :meth:`run_statistics` and :meth:`generate_plots`
    can be overridden when an analysis needs them. The :meth:`run` method calls
    each stage in order so a scientist can execute the entire pipeline with a
    single command. Any tables or figures produced by the analysis are saved
    beneath ``<output_dir>/analysis_pipeline`` so collaborators always know
    where to look for derived artefacts.
    """

    #: Human readable identifier used for folder names and command line choices.
    name: str = "projection_analysis"

    def __init__(
        self,
        base_path: Path | str,
        *,
        projection_dir_name: str = "simple_projections",
        output_dir: Optional[Path | str] = None,
        channel_filter: Optional[Sequence[str]] = None,
    ) -> None:
        """Set up common paths used by the analysis."""

        self.base_path = Path(base_path).expanduser().resolve()
        self.projection_dir_name = projection_dir_name
        self.projection_root = self.base_path / self.projection_dir_name
        self.output_dir = (
            Path(output_dir).expanduser().resolve()
            if output_dir is not None
            else self.base_path / "analysis_results" / self.name
        )

        # Derived outputs (tables, plots) are stored beneath ``analysis_pipeline``
        # to emphasise that they originate from a downstream analysis stage.
        self.pipeline_dir = self.output_dir / "analysis_pipeline"
        self.data_dir = self.pipeline_dir / "data"
        self.figures_dir = self.pipeline_dir / "figures"

        # Subclasses can register additional tables for saving once the pipeline
        # finishes running.
        self.additional_tables: Dict[str, pd.DataFrame] = {}

        # Restrict processing to a subset of channels when requested. Channel
        # names are normalised to match the filenames produced by the projection
        # export utility (case-insensitive, punctuation stripped).
        self.channel_filter_names: tuple[str, ...] = tuple(channel_filter or ())
        normalised = {
            self._normalise_channel_name(name)
            for name in self.channel_filter_names
            if name
        }
        self.channel_filter: Optional[set[str]] = normalised or None

        # ``save_outputs`` and ``save_figure`` populate these lists so the CLI
        # can report exactly what was created during the run.
        self.saved_table_paths: list[Path] = []
        self.saved_figure_paths: list[Path] = []

        # The manifest lists every file we plan to inspect. ``results`` stores
        # the processed measurements calculated from those files. Subclasses
        # fill these with pandas DataFrames so downstream steps (saving, plots)
        # can reuse them without needing to re-run heavy computations.
        self.manifest: Optional[pd.DataFrame] = None
        self.results: Optional[pd.DataFrame] = None

    # ------------------------------------------------------------------
    # Pipeline orchestration
    # ------------------------------------------------------------------
    def run(self) -> None:
        """Execute the end-to-end pipeline for the analysis."""

        self.saved_table_paths.clear()
        self.saved_figure_paths.clear()
        self.additional_tables.clear()

        if self.channel_filter_names:
            print(
                f"[{self.name}] Restricting to channels: "
                f"{', '.join(self.channel_filter_names)}",
                flush=True,
            )

        print(f"[{self.name}] Importing projection manifest ...", flush=True)
        self.manifest = self.import_data()
        manifest_len = len(self.manifest) if self.manifest is not None else 0
        print(
            f"[{self.name}]  -> catalogued {manifest_len} projection file(s).",
            flush=True,
        )

        print(f"[{self.name}] Processing projection statistics ...", flush=True)
        self.results = self.process_data(self.manifest)
        results_len = len(self.results) if self.results is not None else 0
        print(
            f"[{self.name}]  -> generated per-image statistics for {results_len} TIFF(s).",
            flush=True,
        )

        print(f"[{self.name}] Running group statistics ...", flush=True)
        self.run_statistics()
        print(f"[{self.name}]  -> group statistics stage complete.", flush=True)

        print(f"[{self.name}] Creating figures ...", flush=True)
        self.generate_plots()
        print(
            f"[{self.name}]  -> created {len(self.saved_figure_paths)} figure(s) for export.",
            flush=True,
        )

        print(f"[{self.name}] Saving data tables ...", flush=True)
        self.save_outputs()
        print(
            f"[{self.name}]  -> wrote {len(self.saved_table_paths)} CSV table(s) to disk.",
            flush=True,
        )

        self.export_results()

    # ------------------------------------------------------------------
    # Mandatory steps
    # ------------------------------------------------------------------
    @abc.abstractmethod
    def import_data(self) -> pd.DataFrame:
        """Discover and catalogue the projection files used by the analysis."""

    @abc.abstractmethod
    def process_data(self, manifest: pd.DataFrame) -> pd.DataFrame:
        """Perform the core numerical processing for the analysis."""

    # ------------------------------------------------------------------
    # Optional steps for subclasses to extend
    # ------------------------------------------------------------------
    def run_statistics(self) -> None:
        """Run statistical comparisons across processed results."""

    def generate_plots(self) -> None:
        """Produce figures summarising the analysis."""

    def save_outputs(self) -> None:
        """Persist intermediate artefacts such as CSV files."""

        self.pipeline_dir.mkdir(parents=True, exist_ok=True)
        self.data_dir.mkdir(parents=True, exist_ok=True)

        if self.manifest is not None:
            manifest_path = self.data_dir / "manifest.csv"
            self.manifest.to_csv(manifest_path, index=False)
            self.saved_table_paths.append(manifest_path)
            print(
                f"[{self.name}]     saved manifest -> {manifest_path}",
                flush=True,
            )

        if self.results is not None:
            results_path = self.data_dir / "results.csv"
            self.results.to_csv(results_path, index=False)
            self.saved_table_paths.append(results_path)
            print(
                f"[{self.name}]     saved per-image results -> {results_path}",
                flush=True,
            )

        for filename, table in self.additional_tables.items():
            target = filename if filename.lower().endswith(".csv") else f"{filename}.csv"
            table_path = self.data_dir / target
            table.to_csv(table_path, index=False)
            self.saved_table_paths.append(table_path)
            print(f"[{self.name}]     saved table -> {table_path}", flush=True)

    # ------------------------------------------------------------------
    # Convenience helpers for subclasses
    # ------------------------------------------------------------------
    def register_table(self, filename: str, table: pd.DataFrame) -> None:
        """Queue an additional table to be written by :meth:`save_outputs`."""

        if not filename:
            raise ValueError("filename must be a non-empty string")
        self.additional_tables[filename] = table

    def save_figure(
        self,
        figure: Figure,
        stem: str,
        *,
        formats: Sequence[str] = ("svg", "png"),
        dpi: int = 300,
        metadata: Optional[Dict[str, str]] = None,
    ) -> None:
        """Persist a Matplotlib figure in the analysis figures directory."""

        if Figure is None:
            raise RuntimeError(
                "matplotlib is required to save figures but could not be imported."
            )
        if not stem:
            raise ValueError("stem must be a non-empty string")

        self.figures_dir.mkdir(parents=True, exist_ok=True)
        for ext in formats:
            ext = ext.lower().lstrip(".")
            output_path = self.figures_dir / f"{stem}.{ext}"
            save_kwargs = {
                "format": ext,
                "dpi": dpi,
                "bbox_inches": "tight",
            }
            if metadata:
                save_kwargs["metadata"] = metadata
            figure.savefig(output_path, **save_kwargs)
            self.saved_figure_paths.append(output_path)
            print(f"[{self.name}]     saved figure -> {output_path}", flush=True)

    def export_results(self) -> None:
        """Hook for exporting artefacts to external systems."""

        # Subclasses can override this to push data to collaborators or shared
        # drives. The default implementation intentionally does nothing.
        return None

    # ------------------------------------------------------------------
    # Channel helpers
    # ------------------------------------------------------------------
    @staticmethod
    def _normalise_channel_name(name: str) -> str:
        """Return a case-insensitive, sanitised channel identifier."""

        cleaned = "".join(
            char if char.isalnum() or char in {"-", "_"} else "_"
            for char in name
        )
        cleaned = cleaned.strip("_.")
        return cleaned.lower()

    def _channel_is_selected(self, channel: str) -> bool:
        """Return True when the supplied channel passes the filter."""

        if self.channel_filter is None:
            return True
        return self._normalise_channel_name(channel) in self.channel_filter

    def _filter_channels(self, channels: Iterable[str]) -> list[str]:
        """Filter an iterable of channels using the current selection."""

        return [
            channel
            for channel in channels
            if self._channel_is_selected(channel)
        ]
